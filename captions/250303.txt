1
00:00:02,330 --> 00:00:08,670
[Auto-generated transcript. Edits may have been applied for clarity.]
Should be recording underway. Welcome back to week six.

2
00:00:08,760 --> 00:00:13,010
More than halfway through the spring break. Um.

3
00:00:13,530 --> 00:00:17,460
Excuse me. Start off with the usual.

4
00:00:19,620 --> 00:00:29,639
Magic number for today, and then check in about where we are and what we're going to be doing this coming week.

5
00:00:29,640 --> 00:00:35,219
Some of the traditional highlights of statistical mechanics into one another

6
00:00:35,220 --> 00:00:41,520
next touches on things that some of you may well have seen before you took the,

7
00:00:41,540 --> 00:00:49,649
uh, the joint physics math programs. We're seeing some things like the ideal gas law and the kind of a cycle back in the first year

8
00:00:49,650 --> 00:00:56,760
that we will hopefully add to what you've seen by deriving those from a more solid foundation.

9
00:00:58,140 --> 00:01:06,690
Um, but yeah, focusing on these ideal gases and their applications to thermodynamic cycles this week,

10
00:01:07,440 --> 00:01:12,930
some quick logistical comments before we get back underway with that.

11
00:01:13,590 --> 00:01:16,800
Um, next homework assignment is due Friday.

12
00:01:17,250 --> 00:01:25,800
It is more of a traditional homework assignment. So I squeezed into one bit where some numerical computing may be helpful for you.

13
00:01:26,580 --> 00:01:30,650
And some some of you have already submitted that. So it's okay.

14
00:01:30,750 --> 00:01:40,680
Not going to be too much of a burden this week. There was a recurring problem with last Wednesday's lecture captures of the video of the notes,

15
00:01:40,680 --> 00:01:46,440
where all their audio was disconnected from the recording.

16
00:01:46,480 --> 00:01:51,570
I think I figured out why the software did that. I have to make sure it doesn't happen again.

17
00:01:52,290 --> 00:01:56,010
And yes, finally, the previous assignment.

18
00:01:56,550 --> 00:02:03,720
Uh, from what we can a bit ago with the computer assignment, some overdue submissions are still trickling in.

19
00:02:04,230 --> 00:02:10,170
The ultimate Cut-Off for those is Wednesday, at which point we'll be able to release the model solutions.

20
00:02:10,920 --> 00:02:18,930
And I'll probably still be continuing with the marking while I do that, it will come back up as soon as I can get through it.

21
00:02:20,550 --> 00:02:24,330
And hopefully due to the different nature of the next computer assignment.

22
00:02:24,360 --> 00:02:31,200
Don't forget the feedback from the assignment to charge ahead with the more traditional homework assignment.

23
00:02:33,150 --> 00:02:35,280
So it's not about logistics.

24
00:02:35,280 --> 00:02:47,010
Unless there are questions on that topic, I can get back to physics and mathematics and just reorient after a few days away,

25
00:02:47,490 --> 00:03:01,500
that we are focusing for several weeks on applications of the canonical ensemble with a fixed temperature from a large external reservoir,

26
00:03:02,280 --> 00:03:11,490
and our current application is an ideal gas is not attracting particles governed by classical Newtonian mechanics.

27
00:03:13,680 --> 00:03:24,660
And non-relativistic. Our starting point for mathematical analyses, as always in the canonical ensemble, is the partition function,

28
00:03:26,160 --> 00:03:33,059
and we computed these and the corresponding Helmholtz free energies, um, for a couple of cases,

29
00:03:33,060 --> 00:03:40,590
all of which involve continuously varying energies in the partition function.

30
00:03:40,590 --> 00:03:51,340
So uncountably infinite number of microstates that required regularisation, removal of our cut-off of discretized momenta, and then, uh,

31
00:03:51,420 --> 00:03:57,060
recovery of simple expressions for the case of both indistinguishable particles,

32
00:03:58,080 --> 00:04:05,160
which are related to distinguishable particles by a factor of one over the number of particles factorial,

33
00:04:05,250 --> 00:04:13,320
that comes the different ways these n particles can be given labels in the distinguishable case, and in both cases,

34
00:04:14,220 --> 00:04:19,140
thanks to the non-interacting ideal approximation being put in here,

35
00:04:19,650 --> 00:04:25,800
the many particle partition functions are just in copies of the single particle partition function.

36
00:04:26,190 --> 00:04:34,379
So said sub one to the power, and then we can write down a very compact expression for that single particle

37
00:04:34,380 --> 00:04:40,080
partition function as the ratio of the volume in which the gas the gas occupies,

38
00:04:41,430 --> 00:04:48,059
divided by what we can think of as this occupied volume with a different wavelength

39
00:04:48,060 --> 00:04:52,879
cubed that depends on the temperature and various fundamental constants.

40
00:04:52,880 --> 00:04:59,790
So specifically it is this root two pi times.

41
00:05:00,050 --> 00:05:03,600
Wisconsin squared over the mass is known as the.

42
00:05:03,600 --> 00:05:08,549
The sick particles times the temperature, and from the starting points.

43
00:05:08,550 --> 00:05:13,110
I should say I don't usually believe her face, which seem like there's so much,

44
00:05:13,110 --> 00:05:24,510
but it will be useful to have these crashing going around as we go forward and look at, um, mixing and entropy in these ideal gases today.

45
00:05:25,350 --> 00:05:34,170
So from that starting point of the partition functions and help its free energy, we got a few predictions.

46
00:05:34,860 --> 00:05:39,360
First, in both cases of distinguishable and indistinguishable particles,

47
00:05:40,290 --> 00:05:46,770
the internal energy took a very simple form three times the number of particles times the temperature.

48
00:05:48,570 --> 00:05:52,350
The entropy is the indistinguishable case.

49
00:05:53,550 --> 00:06:05,970
It had the same functional dependence, uh, linear and n plus n times the log of this volume, the occupied volume ratio.

50
00:06:07,680 --> 00:06:13,560
Um, the same types of terms show up in the entropy for the distinguishable case.

51
00:06:13,890 --> 00:06:20,730
But we saw that the ability to label particles in the distinguishable case allowed for more information in the system,

52
00:06:21,150 --> 00:06:25,590
and hence more entropy, a larger the near term,

53
00:06:25,590 --> 00:06:40,470
although a smaller logarithmic term that we can relate to the change in the occupied volume in the case of the particles can be distinguished.

54
00:06:42,750 --> 00:06:49,980
So based on those results, we started looking at the process of particle mixing that we will finish today.

55
00:06:52,440 --> 00:07:00,179
With a focus on. How this connects to the second law of thermodynamics.

56
00:07:00,180 --> 00:07:05,160
The statement that the entropy of the universe always has to increase as time passes.

57
00:07:06,630 --> 00:07:17,670
Um, so far at the end of Wednesday, we started out by, um, reviewing the basic setup.

58
00:07:18,210 --> 00:07:29,820
We start off with two uh, independent, formalised canonical systems that are in contact with themselves with the same large external reservoir.

59
00:07:30,660 --> 00:07:34,860
They have a wall separating them. That means their particles cannot mix.

60
00:07:35,910 --> 00:07:45,150
They remove that mass to get an intermediate combined system C, where particle exchange can occur between the left and right halves,

61
00:07:46,380 --> 00:07:52,560
and then we reinsert the wall and ends up with something that looks kind of like our starting point,

62
00:07:53,940 --> 00:08:03,929
but now with potentially different entropies that we want to confront against the statement of that second law of thermodynamics.

63
00:08:03,930 --> 00:08:10,590
And so far we saw that in the case of indistinguishable particles,

64
00:08:11,190 --> 00:08:20,280
the entropy of the combined system was exactly equal to the entropy of the initial two subsystems.

65
00:08:22,620 --> 00:08:27,030
Which is consistent with the second law of thermodynamics,

66
00:08:27,630 --> 00:08:35,940
the entropy has not decreased as we removed that wall had stayed the same from S8 plus SB into SC.

67
00:08:38,400 --> 00:08:46,500
Um, once we do finish this, if we do, we should be able to take a look at so-called equations of state.

68
00:08:48,000 --> 00:08:49,650
We'll just have that to look forward to.

69
00:08:50,400 --> 00:09:02,550
Um, coming up, more calls to see if there are any questions about our starting point of this exercise of mixing versus the second law.

70
00:09:03,840 --> 00:09:16,920
Um. And not seeing any, we can start thinking about the final stage in here.

71
00:09:17,640 --> 00:09:23,960
Reinserting the rule and re separating these two systems, which is the tricky bit.

72
00:09:23,970 --> 00:09:33,600
And that's why it was left for this week. So when we're separate the systems.

73
00:09:38,010 --> 00:09:48,540
The basic concepts are idea is exactly the same as when we looked at heat exchange and saw the emergence of the second law in the first place.

74
00:09:48,540 --> 00:09:52,530
So back in unit two of looking at the micro canonical ensemble,

75
00:09:52,920 --> 00:09:59,820
temporarily allowing thermal contact and then taking the two micro canonical ensembles back into isolation, we.

76
00:09:59,900 --> 00:10:08,900
Saw that the entropy after that process had to count up or sum over all of the possible ways that

77
00:10:09,260 --> 00:10:14,390
the energy could end up distributed between those two subsystems once they were re separated.

78
00:10:15,080 --> 00:10:24,260
And just the same here. We need to account for all possible distributions of particles.

79
00:10:26,630 --> 00:10:30,650
After the ball is reinserted to separate those two systems.

80
00:10:30,650 --> 00:10:36,410
So to call this sort of particle divisions.

81
00:10:38,480 --> 00:10:53,990
Um and we can organise this sum that we have to do by saying that new particles end up in the system on the left hand side,

82
00:10:54,590 --> 00:11:05,230
which means that all the other particles to n minus nu will be here, ending up in the same system being prime.

83
00:11:06,260 --> 00:11:11,610
Uh, on here on the right hand side of this division. Um.

84
00:11:14,760 --> 00:11:26,639
So we did have some over this new from the case of zero, where all the particles are right all the way up to two end for all of the two,

85
00:11:26,640 --> 00:11:30,960
and particles from both of the initial subsystems end up in the left.

86
00:11:32,460 --> 00:11:41,010
And certainly we have to do this at the level of the partition function, which is the fundamental, uh, defining feature of our system.

87
00:11:41,880 --> 00:11:47,490
So we can't just compute the entropy in each of these cases and some of the entropies.

88
00:11:48,090 --> 00:11:53,010
Um, that would be if you dig into the mathematics and try to do that,

89
00:11:53,050 --> 00:12:01,950
you'll see that it's effectively converting a sum of the average into a, ah, sorry algorithm of, of of a sum into a sum of logarithms.

90
00:12:03,390 --> 00:12:15,840
Um, the two are not the same. It is the partition function that has to be put through this summation process, and only then from there,

91
00:12:16,230 --> 00:12:25,770
once we have the partition function, will we be able to go through the procedure to extract the entropy from it.

92
00:12:27,420 --> 00:12:36,410
So the partition function for each of these possible particle distributions we can call it z solution.

93
00:12:37,320 --> 00:12:43,200
And it will have one factor of the indistinguishable partition function.

94
00:12:43,200 --> 00:12:48,510
For new particles in the left system with volume the temperature T.

95
00:12:49,440 --> 00:12:55,830
And then, because these systems are independent, has been reinserted to separate them.

96
00:12:56,520 --> 00:13:02,670
Every microstate in each system can be adopted at the same time as every microstate in the other system.

97
00:13:03,000 --> 00:13:07,350
So we just get direct multiplication with the.

98
00:13:08,690 --> 00:13:18,920
Indistinguishable particle partition function for the other two and minus new particles on the other side S0 with volume v and temperature T,

99
00:13:20,630 --> 00:13:30,740
and in went through the model ourselves what these partition functions are depending on and v and t,

100
00:13:31,460 --> 00:13:38,480
so certainly the one is the same between both subsystems which is convenient.

101
00:13:39,830 --> 00:13:47,420
We will have a one over new factorial from z I on the left.

102
00:13:48,020 --> 00:14:05,450
We will have a one over two and minus new factorial in the z I on the right, and then new factors of the volume over lambda cubed multiplied by.

103
00:14:07,740 --> 00:14:11,160
Two and minus new factors of that same.

104
00:14:12,900 --> 00:14:16,680
Factor volume over lambda cubed to and minus new power.

105
00:14:19,410 --> 00:14:23,310
Plus new and minus new powers cancel out.

106
00:14:24,510 --> 00:14:32,639
And if we immediately jump to the partition function of our final stage, what's things?

107
00:14:32,640 --> 00:14:46,230
Are we separated? We have to sum from new going to zero up to two end of the new, which we have now determined to be.

108
00:14:48,840 --> 00:14:59,700
Our usual single particle partition function raised to the two and power with a one over new factorial and a one over two n minus new factorial.

109
00:15:02,730 --> 00:15:12,480
The. Single particle partition functions here have no dependence on you at all that is cancelled out so they can come outside of that sum.

110
00:15:14,310 --> 00:15:27,600
This, uh, factor of one over new factorial times two and minus new factorial looks tantalisingly like what we would get out of a binomial coefficient.

111
00:15:28,230 --> 00:15:37,260
If we had two n choose nu. The only difference is in overall factor of two n factorial that would show up in the numerator.

112
00:15:38,670 --> 00:15:48,120
So we can reorganise this. Pull the constant factor out front.

113
00:15:49,020 --> 00:15:56,429
And then sum over new binomial coefficient of two and choose nu and then cancel

114
00:15:56,430 --> 00:16:02,129
out the one over two n or cancel out the two n factorial with one over two.

115
00:16:02,130 --> 00:16:07,110
Inject trial to get back to the intermediate to expression that we had here.

116
00:16:09,210 --> 00:16:16,980
And this just slightly at the beginning of the screen shows there's the end of that equations.

117
00:16:20,160 --> 00:16:26,400
So all right so far. Because now the fun really begins when we.

118
00:16:29,220 --> 00:16:33,240
Connect this partition function.

119
00:16:33,750 --> 00:16:45,570
Our underlying this effectively definition of the system to run the entropy through the derivative with respect to temperature of.

120
00:16:48,750 --> 00:16:52,050
The negative Helmholtz free energy t log z.

121
00:16:54,420 --> 00:16:59,040
And we put in the logarithm of this expression here.

122
00:17:01,140 --> 00:17:10,380
We will have to keep track of the appearance of um temperature dependence in at thermal different wavelengths.

123
00:17:11,680 --> 00:17:14,729
We can bring down that to n power in the logarithm.

124
00:17:14,730 --> 00:17:18,960
That's a constant that comes out in front of that partial derivative.

125
00:17:21,570 --> 00:17:28,410
Then we have this t log its volume over thermal degree wavelengths cubed.

126
00:17:28,410 --> 00:17:31,500
Remembering that that is temperature dependent.

127
00:17:34,320 --> 00:17:41,370
And then the two n factorial uh factor there is constant.

128
00:17:41,810 --> 00:17:47,450
It's multiplying by the t derivative of t with respect to t is just one.

129
00:17:47,460 --> 00:17:58,440
So we can use the properties of logs to make that one over two n factorial factorial a negative log of two factorial.

130
00:17:59,010 --> 00:18:03,210
And then we have the log.

131
00:18:05,640 --> 00:18:16,320
Of this disgusting sum of binomial coefficients u ranging from 0 to 2.

132
00:18:16,320 --> 00:18:20,219
And so that is the formal entropy that we have.

133
00:18:20,220 --> 00:18:28,680
And I should stop here and point out more concretely what I was saying earlier about taking a walk away sum rather than a sum of logs.

134
00:18:30,960 --> 00:18:39,270
So it's important that we start from the partition function for our system and not try to treat that

135
00:18:39,270 --> 00:18:46,110
new as though it were an independent possibility that could give an independent entropy to be solved.

136
00:18:47,310 --> 00:19:00,600
Maybe the key point to take away from this expression here is just that it is complicated and a real pain to deal with,

137
00:19:00,600 --> 00:19:13,950
even in the simplest situations. So in this week's tutorial, we will work on setting up a simplified situation like that to,

138
00:19:14,520 --> 00:19:22,260
uh, have a go at actually evaluating this entropy in the in an example case.

139
00:19:23,640 --> 00:19:26,670
Remember back on medium heat exchange? We didn't try to evaluate this.

140
00:19:26,670 --> 00:19:31,830
We just said that the the initial distribution was one possible term.

141
00:19:31,870 --> 00:19:36,739
There were additional negative terms. Hence the entropy was not decreasing.

142
00:19:36,740 --> 00:19:40,230
And we declared victory at that point. Um.

143
00:19:42,570 --> 00:19:49,020
But rather than trying to grind through all of these logs of factorials binomial expressions,

144
00:19:50,070 --> 00:19:56,550
what we should do if we want to get anything done today is simplify this with an approximation.

145
00:19:57,600 --> 00:20:08,340
It will be, um, not quite the same as the simplifications that we looked at for high low temperature limits, uh, last week and even the week before.

146
00:20:13,170 --> 00:20:20,850
But we are able to do something by thinking about, uh, last week's tutorials, exercises related to entropy that,

147
00:20:21,720 --> 00:20:32,160
um, you are hopefully having a look through last weekend and through this week.

148
00:20:32,160 --> 00:20:46,680
We'll wrap up discussing them on Thursday. But those considerations of entropy bounds motivate an approximation that gets credited to J.

149
00:20:46,710 --> 00:20:59,400
Willard Gibbs. He was seen before he introduced the concepts of thermodynamics or statistical ensembles and the terminology of statistical mechanics.

150
00:21:00,510 --> 00:21:14,460
So the argument that is being illustrated by the tutorial exercise on entropy bounds is that for large numbers of particles,

151
00:21:16,440 --> 00:21:26,230
essentially all of the entropy in this file system summing over the particle divisions from 0 to 2 ends.

152
00:21:26,790 --> 00:21:36,780
Essentially all of that. Is accounted for just from considering the case of even distribution,

153
00:21:38,190 --> 00:21:48,450
by which I mean that the number of particles in each side and in a prime is equal to n b prime, and is.

154
00:21:48,450 --> 00:21:55,350
Therefore both of those are equal to n. The initial numbers that we started off with at the start of this procedure.

155
00:21:56,940 --> 00:22:10,680
Um, so if you actually, you might have noticed and wondered in this illustration that I had already anticipated this approximation, this argument,

156
00:22:11,130 --> 00:22:24,510
and set the number of particles after we separated system two and, um, the initial number, rather than letting that be a new addition to a minus two.

157
00:22:26,250 --> 00:22:37,290
So the reason that this is a good approximation is just that there are many more ways of getting this even distribution than the very special,

158
00:22:37,650 --> 00:22:49,770
very unusual situations where we have just before we sort the roll, all of the particles in the system on either one side or the other.

159
00:22:50,190 --> 00:22:53,310
It's not something we expect to happen to, say, the air in this room.

160
00:22:53,790 --> 00:22:58,470
So it's not something we should expect to happen to this, uh, box in our thought experiment,

161
00:23:00,030 --> 00:23:07,350
if we put a wall down the middle of this room, we can expect equal numbers of particles on either side of that wall.

162
00:23:08,400 --> 00:23:18,330
And then that makes it actually very easy to find the final entropy, because it is actually the initial entropy.

163
00:23:19,530 --> 00:23:29,130
We have two systems of indistinguishable particles, each within particle particles over here temperature T, which is our starting point.

164
00:23:29,880 --> 00:23:33,870
And what we saw last Wednesday was equal to the entropy of the combined system.

165
00:23:35,040 --> 00:23:38,399
So this is all consistent with the second law of thermodynamics.

166
00:23:38,400 --> 00:23:50,160
It is the, uh, special case where there is no change in the entropy of the system as we go through this whole process,

167
00:23:51,600 --> 00:23:59,010
which in particular means that the process of removing the wall can be reversed and the law could be put back in,

168
00:24:00,480 --> 00:24:09,780
um, essentially going in either direction without needing any anything else to happen.

169
00:24:11,160 --> 00:24:13,320
So this is um.

170
00:24:16,350 --> 00:24:24,300
Effectively the case you may have been considering, if we think about the air in this room as an ideal gas covered by the canonical ensemble,

171
00:24:24,810 --> 00:24:28,110
and there's a similar ideal gas of air in the corridor.

172
00:24:28,800 --> 00:24:34,860
If we open the door between this room and the corridor, we don't expect anything dramatic to happen,

173
00:24:35,280 --> 00:24:41,250
and we can smoothly shut that door again without seeing any.

174
00:24:42,090 --> 00:24:51,210
Big, dramatic, observable effects. Um. We can so just say that the opening and closing of a door is reversible.

175
00:24:51,840 --> 00:24:55,530
Um, but there these very good approximations.

176
00:24:57,540 --> 00:25:04,710
So in the end, a fairly simple result thanks to the Gibbs approximation.

177
00:25:05,250 --> 00:25:11,460
Entropy just stays the same. As we go through our whole particle exchange and mixing process.

178
00:25:12,120 --> 00:25:19,080
Are there any questions about the indistinguishable case here before we want to consider the case of distinguishable particles?

179
00:25:25,630 --> 00:25:30,520
I see shaking heads. So we can charge forward.

180
00:25:30,640 --> 00:25:44,110
And just like we did for the computation of the internal energy and entropy itself, going from the indistinguishable case to the distinguishable case,

181
00:25:44,110 --> 00:25:56,620
we just need to get rid of the, uh, in factorials that appear in the case of indistinguishable particles rather than distinguishable ones.

182
00:25:57,880 --> 00:26:06,070
So the initial is not yet the start of our three step process,

183
00:26:06,070 --> 00:26:16,120
as the sum of the entropies in the two systems is now just twice the distinguishable entropy for n particles and volume for temperature T,

184
00:26:16,120 --> 00:26:19,329
so rather than five.

185
00:26:19,330 --> 00:26:26,890
And that is a result here rather than a three, and it is A5N.

186
00:26:31,890 --> 00:26:38,130
Plus. There are two and invoke of.

187
00:26:40,560 --> 00:26:52,379
The v over lambda cubed. Once we combine the systems and have a C that is a system of distinguishable particles.

188
00:26:52,380 --> 00:26:58,710
Now with twice the number of particles in twice the volume still at the same temperature.

189
00:26:59,340 --> 00:27:07,499
So we have five halves times two n gives us the same five n and we have again two.

190
00:27:07,500 --> 00:27:15,480
And here generate log of twice the volume over something that depends only on the temperature.

191
00:27:17,520 --> 00:27:22,590
So this is where we start to see differences popping up.

192
00:27:23,730 --> 00:27:31,080
In the indistinguishable case, the combined and initial entropies were exactly the same here.

193
00:27:31,560 --> 00:27:34,320
There is one key difference,

194
00:27:35,010 --> 00:27:43,410
and two that is snuck in there and is not being cancelled out by having an N in the occupied volume to double and cancel it.

195
00:27:44,700 --> 00:27:52,980
So if we look at the difference going from the initial entropy to the entropy design system,

196
00:27:53,940 --> 00:28:00,900
that is just going to be two and log two, everything else cancels out in the difference.

197
00:28:02,250 --> 00:28:08,070
And this is a positive number, especially when n is very large.

198
00:28:08,400 --> 00:28:14,190
And this positive number is known as the mixing entropy.

199
00:28:14,630 --> 00:28:24,150
I call delta s so mix. So.

200
00:28:26,640 --> 00:28:36,060
The non-zero and the particular positive value of this entropy is what we would expect from the second law of thermodynamics.

201
00:28:36,540 --> 00:28:46,800
We do something to the universe. The entropy increases as a result, and if we repeat our Gibbs approximation,

202
00:28:46,860 --> 00:28:56,339
argue that you will end up with the same n particles on either side of our reinserted.

203
00:28:56,340 --> 00:29:02,760
Well, that re separates the systems. You can jump right to the final entropy.

204
00:29:04,000 --> 00:29:17,700
Whoops D is a subscript twice the distinguishable entropy for envy and t that is S not n it is less than SC,

205
00:29:18,600 --> 00:29:25,890
and that would indicate a decrease in the entropy from reinserting the the wall.

206
00:29:28,740 --> 00:29:34,410
Which is exactly what the second law tells us cannot happen.

207
00:29:36,870 --> 00:29:49,980
So something has gone wrong in the argument that we've gone through for the case of distinguishable particles and this outcome.

208
00:29:50,760 --> 00:30:03,780
This argument is popularly known as the Gibbs paradox, which is not entirely fair to Gibbs, because he is the person who,

209
00:30:04,560 --> 00:30:12,150
um, he did notice that this arose, but also explained why it happened, what went wrong, and how to get around this.

210
00:30:12,540 --> 00:30:20,280
I'm sure that there is actually no paradox in our civil mechanics analysis of the world.

211
00:30:21,420 --> 00:30:30,140
So any questions about the results that we are seeing before we go on, say what's right about them?

212
00:30:43,020 --> 00:30:51,240
It is possible that some of you may already have latched onto the essential idea that's going on here.

213
00:30:52,350 --> 00:30:58,560
So if we have to search the particles in this whole set up, that means we can label them.

214
00:30:59,670 --> 00:31:08,160
I've already used ABC for the system, so let me call the particles one through six here in our illustration.

215
00:31:09,000 --> 00:31:13,380
And once we remove all these six particles,

216
00:31:14,010 --> 00:31:23,460
we'll be able to go back and forth from the left to the right and back again in the overall confined system.

217
00:31:24,600 --> 00:31:30,450
Once we allow that to have to go on for some times in the system, we have it.

218
00:31:31,050 --> 00:31:37,890
We reinsert the wall and the particles will know they are distinguishable.

219
00:31:37,890 --> 00:31:43,200
We are able to see what labels they have. And this is one possibility.

220
00:31:44,010 --> 00:31:49,980
We have one, four and five on the left and two, three and six those particles on the right.

221
00:31:53,220 --> 00:31:57,960
And this is not, in fact the system that we started off with.

222
00:31:58,440 --> 00:32:04,019
The way that calculation here, um, predicted,

223
00:32:04,020 --> 00:32:08,459
saying that the final entropy was equal to the original one by virtue of having

224
00:32:08,460 --> 00:32:14,740
twice the entropy for this distribution of systems that still do have in particles,

225
00:32:14,760 --> 00:32:21,120
and Gibbs, the Gibbs approximation that there will be and particles on either side of the wall does continue to hold.

226
00:32:22,440 --> 00:32:29,850
But now the labels on those particles so we can distinguish in this case are different from our starting point.

227
00:32:30,450 --> 00:32:35,130
And with distinguishable particles, that difference gives us a different system,

228
00:32:36,270 --> 00:32:42,450
even though the overall number uniformity of a temperature are all still the same.

229
00:32:44,610 --> 00:32:59,460
Sorry. The formal way of phrasing this is to say that distinguish ability means there is more information accessible in principle,

230
00:33:00,300 --> 00:33:04,110
even if we chose not to measure those labels or didn't know anything about them.

231
00:33:04,560 --> 00:33:11,910
The pure fact that we could label the particles if we wanted means the information is intrinsically present.

232
00:33:13,330 --> 00:33:26,350
In the system we are analysing. The information content, as we have seen, has an effect on the entropy even for a fixed number of particles.

233
00:33:26,650 --> 00:33:33,730
We saw that with distinguishable versus indistinguishable spins um, back a couple of weeks ago.

234
00:33:34,570 --> 00:33:40,480
And this additional information then feeds into having additional microstates.

235
00:33:41,470 --> 00:33:47,290
And with the large numbers of particles we expect to have in statistical settings,

236
00:33:47,680 --> 00:33:58,120
there will be vastly more possible microstates, um, based on that in factorial, different ways of labelling.

237
00:34:00,130 --> 00:34:08,470
The particles these microstates will differ only by having different labels on the different particles.

238
00:34:10,720 --> 00:34:21,490
And all of those additional microstates are accompanying the initial system that we started off with.

239
00:34:22,480 --> 00:34:31,030
Omega A and Omega B that have this particular labelling one, two, three, four, five, six on the left and right, respectively.

240
00:34:31,900 --> 00:34:34,330
That is still a possibility when we're separate things.

241
00:34:34,780 --> 00:34:40,600
And then there are more possibilities like one, four, five on the left and two three, six on the right.

242
00:34:42,820 --> 00:34:53,650
So all of that is to say that this additional information leading to additional microstates is directly reflected in.

243
00:34:56,620 --> 00:35:03,850
A larger value of the entropy, even with the particle number.

244
00:35:06,070 --> 00:35:14,590
Ending up at its starting point. So we know that well.

245
00:35:15,370 --> 00:35:23,590
This basic argument tells us that the entropy increases going from the initial state to the final one.

246
00:35:24,610 --> 00:35:32,590
And if we go through. The full complicated calculation that.

247
00:35:36,340 --> 00:35:46,180
Involves incorporating information about the particle labels into our studied expression for the entropy in full glory.

248
00:35:46,210 --> 00:35:50,560
Even with the Gibbs approximation applied, we have to keep track of labels.

249
00:35:50,560 --> 00:36:02,050
In this case, uh, there is complicated calculations that are going to give us diminishing returns to actually grind through them here and now.

250
00:36:03,310 --> 00:36:16,090
They do confirm the lesson of the second law that, yeah, the final entropy has to be greater not only than the starting one.

251
00:36:16,510 --> 00:36:24,700
And that decreasing compared to both the starting entropy and the intermediate entropy of the combined system,

252
00:36:24,700 --> 00:36:40,870
which was where our more, uh, our glib argument here turned out to reflect this information and go astray for that reason.

253
00:36:42,460 --> 00:36:46,690
So this is exactly what the next tutorial will.

254
00:36:49,810 --> 00:37:01,450
Set up and give you a chance to to work on looking at a simpler case where we don't have independent labels for every different particle,

255
00:37:01,900 --> 00:37:06,850
but that the particles in the two sides are either red or blue.

256
00:37:07,360 --> 00:37:14,050
So red particle always on the left, the old red particles on the left, and all blue particles on the right.

257
00:37:14,800 --> 00:37:17,440
Remove the wall. That makes three separate.

258
00:37:17,830 --> 00:37:28,570
Try to keep track of how residuals should be distributed in the final state, and see that the second law is satisfied.

259
00:37:29,790 --> 00:37:33,219
So questions about this argument,

260
00:37:33,220 --> 00:37:41,740
especially because I have gone through the formal calculation for this much as the a qualitative

261
00:37:41,740 --> 00:37:52,180
argument that then you that it comes out all right if you actually attempt to do the full exercise.

262
00:37:59,660 --> 00:38:08,090
Not seeing. Anybody can draw a line under this whole consideration of mixing and mixing entropy.

263
00:38:08,810 --> 00:38:14,900
I am just summarising the overall takeaway message that.

264
00:38:17,810 --> 00:38:30,740
For the distinguishable case. We have all of these ways of scrambling the labels as particles mix.

265
00:38:31,220 --> 00:38:38,810
And there's essentially zero chance of getting back to the initial, um, labels.

266
00:38:39,050 --> 00:38:47,540
The initial distribution of labels that we started off with. In practice, we can consider it simply impossible.

267
00:38:49,670 --> 00:38:55,580
To get back to our starting points through this particle exchange, uh, process.

268
00:39:07,550 --> 00:39:15,590
Which is just a long winded say as I would it way of saying that we have four distinguishable particles.

269
00:39:15,590 --> 00:39:24,350
At least this mixing of this particle exchange thought experiment is irreversible,

270
00:39:24,950 --> 00:39:33,829
in contrast to the reversibility of having indistinguishable particles that allow us

271
00:39:33,830 --> 00:39:39,140
to open a closed door without dramatically increasing the entropy of the universe.

272
00:39:41,630 --> 00:39:43,870
And the irreversibility of the process.

273
00:39:43,880 --> 00:39:55,580
We can appreciate it by thinking about how the labels get scrambled, and we can more mathematically connected to the increase in entropy.

274
00:39:58,700 --> 00:40:06,830
That results from going through the removal of the wall and its reassertion.

275
00:40:08,930 --> 00:40:16,970
And this is at least one of our very first to the starting point for this entire module.

276
00:40:17,420 --> 00:40:26,690
We looked at some pictures of the drop of dangling foot into a beaker of water and saw that as time passed,

277
00:40:27,230 --> 00:40:31,250
the dye particles were spreading out of diffusing through that water.

278
00:40:31,940 --> 00:40:42,410
And we made the case that even though the underlying laws of physics go just as well, with time flowing in either direction,

279
00:40:43,190 --> 00:40:51,170
we expect processes like that mixing of dyed water to always be moving forward in time,

280
00:40:52,640 --> 00:41:02,990
not reversing so irreversible processes that give us an observable arrow of time emerging from these statistical arguments,

281
00:41:03,530 --> 00:41:06,770
relying on a large number of degrees of freedom.

282
00:41:07,070 --> 00:41:11,690
So that is, you know,

283
00:41:12,260 --> 00:41:23,300
by virtue of developing our understanding of statistical ensembles and the canonical ensemble or partition function toolkit, we have put that.

284
00:41:24,840 --> 00:41:34,470
Uh, observation on a more full mathematical basis and seeing how it arises from statistical mechanics.

285
00:41:37,050 --> 00:41:43,230
So that is the line I want to draw under there.

286
00:41:43,740 --> 00:41:53,910
Thank you. And the next topic, which you may not manage to finish today, but we can certainly make some progress towards it,

287
00:41:53,910 --> 00:41:59,940
is looking at what are called what is kind of the equation of state for ideal gases.

288
00:42:01,170 --> 00:42:17,010
Um, and for this we what we should start by returning to, as always, the fundamental defining, uh, quantity in our canonical system.

289
00:42:18,660 --> 00:42:28,350
So we wrote this review and wrote down at the beginning of today the basic form of the partition function,

290
00:42:28,350 --> 00:42:37,620
whether particles are distinguishable or not. It had the simple dependence on d over lambda cubed raised to the power.

291
00:42:38,700 --> 00:42:51,330
So in both cases. The volume and temperature are showing up in the partition function in this particular combination.

292
00:42:52,110 --> 00:42:57,540
We have a factor of volume. This lambda cubed has a one over square root of t.

293
00:42:58,290 --> 00:43:02,879
So we have one over one over t.

294
00:43:02,880 --> 00:43:10,320
The one half raised to the cube gives us t to the positive three halves over all factors.

295
00:43:10,320 --> 00:43:20,040
And after that. And now we are seeing in these expressions dependence on both the volume and the temperature,

296
00:43:20,040 --> 00:43:24,660
something we highlighted when it first appeared last Wednesday.

297
00:43:25,380 --> 00:43:26,850
You can make this a bit more formal.

298
00:43:28,800 --> 00:43:38,880
Now this is in principle a concept we could have introduced and defined to all the way back when we started talking about spin systems.

299
00:43:41,460 --> 00:43:48,840
But, uh, quantity is like the value of a temperature here we can refer to in general as control parameters.

300
00:43:49,550 --> 00:43:58,350
Um. The first one, the first control parameter we really saw was the magnetic field strength H.

301
00:43:59,490 --> 00:44:04,260
In spin systems we looked at starting in unit two.

302
00:44:06,960 --> 00:44:14,460
The terminology, the basic idea is that these are things parameters that at least in principle,

303
00:44:16,110 --> 00:44:23,760
we or some experimenter can control in the experiments being done.

304
00:44:27,720 --> 00:44:31,650
That is to say that they can be set to a value of interest.

305
00:44:31,650 --> 00:44:35,040
They can be dial up or down, uh, they can be changed.

306
00:44:35,040 --> 00:44:39,570
And the experimenter can then measure the response.

307
00:44:42,060 --> 00:44:46,380
Of the system under study to these changes that are being made.

308
00:44:51,210 --> 00:45:00,240
I will say there is one sovereignty here that sometimes students object to or ask about, which is that we started off,

309
00:45:01,050 --> 00:45:08,160
uh, this formulation of the canonical ensemble by defining it to be characterised by a fixed and unchanging temperature.

310
00:45:08,790 --> 00:45:14,400
And now we're talking about experimentalists with the control over the temperature to change that.

311
00:45:14,760 --> 00:45:21,300
And the question is, does that violate the the foundational assumption of the canonical ensemble?

312
00:45:22,170 --> 00:45:33,990
So it's worth putting in parentheses, a brief aside that the idea we will have in the canonical ensemble when we talk about changing the temperature.

313
00:45:36,090 --> 00:45:48,960
Is that this will be a process of disconnecting our system from its external, uh, thermal reservoir with the initial temperature T II,

314
00:45:49,650 --> 00:45:55,740
and we connect it to a different external reservoir with the final temperature of interest.

315
00:45:56,790 --> 00:46:05,370
Each of the systems with those fixed temperatures are well defined and well behaved in the canonical ensemble,

316
00:46:06,210 --> 00:46:11,910
and we kind of switch off our scrutiny as the process is underway.

317
00:46:11,910 --> 00:46:23,430
We wait for the equilibration with the new fixed temperature and essentially look only at the endpoints of this process and this, um.

318
00:46:25,100 --> 00:46:37,310
Is a way to be able to apply all the, uh, machinery of the canonical ensemble, two processes that change the temperature.

319
00:46:39,590 --> 00:46:45,500
And we will see more examples of this with connecting the connection.

320
00:46:46,370 --> 00:46:48,710
See more examples of this on Wednesday.

321
00:46:49,370 --> 00:47:01,880
Um, this is the essential idea of how some of the network cycles, like the continuous cycle that I mentioned at the start of today,

322
00:47:02,720 --> 00:47:06,620
uh, operator, can be analysed in the framework of the canonical ensemble.

323
00:47:09,860 --> 00:47:18,050
So. The last thing I will say for today is just that we have these control parameters.

324
00:47:18,590 --> 00:47:25,070
In principle we can control them very them and see how the system responds.

325
00:47:25,640 --> 00:47:34,490
It is convenient to keep all but one of them fixed during only one control parameter at a time.

326
00:47:35,390 --> 00:47:41,630
Um is something that we have already considered without the specific terminology of control parameters.

327
00:47:42,350 --> 00:47:43,490
So for instance,

328
00:47:44,090 --> 00:47:53,600
if we looked at how the internal energy of the system responds to a change in the temperature with control parameters like for voice fixed,

329
00:47:54,380 --> 00:47:59,720
this is the heat capacity that you are looking at in your homework.

330
00:48:00,690 --> 00:48:09,710
And we now have an understanding of that. The subscript, the uh, distinguishing the heat capacity at constant volume from other possibilities.

331
00:48:10,610 --> 00:48:19,100
Furthermore, we also looked at how the entropy of the system responds to a change in the energy with the number of particles fixed.

332
00:48:19,980 --> 00:48:27,290
We did this specifically in the micro canonical ensemble, where that was our definition of the inverse temperature that we saw was

333
00:48:27,530 --> 00:48:33,560
equivalent to the behaviour of the energy versus temperature in nonlocal ensemble.

334
00:48:34,250 --> 00:48:38,300
And starting Wednesday, we will add another, uh,

335
00:48:38,720 --> 00:48:49,820
relation to this catalogue and introduce the concept of pressure as the change in the system as its volume is changed.

336
00:48:50,180 --> 00:49:00,620
But for now, if at the end of the hour has long last time to see if there are any questions about what we covered today,

337
00:49:00,980 --> 00:49:14,270
the homework was coming up, obviously, on the tutorial. Um, and if not, I can let you go to enjoy the next few days before we meet again.

